{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Adding a sparsity constraint on the encoded representations\n",
    "# L1正規化を追加した場合\n",
    "from keras.layers import Input, Dense\n",
    "from keras.models import Model\n",
    "\n",
    "from keras import regularizers\n",
    "\n",
    "encoding_dim = 32\n",
    "\n",
    "input_img = Input(shape=(784,))\n",
    "# add a Dense layer with a L1 activity regularizer\n",
    "encoded = Dense(encoding_dim, activation='relu',\n",
    "                activity_regularizer=regularizers.l1(10e-5))(input_img)\n",
    "decoded = Dense(784, activation='sigmoid')(encoded)\n",
    "\n",
    "autoencoder = Model(input_img, decoded)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# this model maps an input to its encoded representation\n",
    "encoder = Model(input_img, encoded)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a placeholder for an encoded (32-dimensional) input\n",
    "encoded_input = Input(shape=(encoding_dim,))\n",
    "# retrieve the last layer of the autoencoder model\n",
    "decoder_layer = autoencoder.layers[-1]\n",
    "# create the decoder model\n",
    "decoder = Model(encoded_input, decoder_layer(encoded_input))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "autoencoder.compile(optimizer='adadelta', loss='binary_crossentropy')\n",
    "# autoencoder.compile(optimizer='adam', loss='binary_crossentropy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.datasets import mnist\n",
    "import numpy as np\n",
    "(x_train, _), (x_test, _) = mnist.load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(60000, 784)\n",
      "(10000, 784)\n"
     ]
    }
   ],
   "source": [
    "x_train = x_train.astype('float32') / 255.\n",
    "x_test = x_test.astype('float32') / 255.\n",
    "x_train = x_train.reshape((len(x_train), np.prod(x_train.shape[1:])))\n",
    "x_test = x_test.reshape((len(x_test), np.prod(x_test.shape[1:])))\n",
    "print (x_train.shape)\n",
    "print (x_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 60000 samples, validate on 10000 samples\n",
      "Epoch 1/200\n",
      "60000/60000 [==============================] - 3s 42us/step - loss: 0.6736 - val_loss: 0.6485\n",
      "Epoch 2/200\n",
      "60000/60000 [==============================] - 2s 42us/step - loss: 0.6284 - val_loss: 0.6090\n",
      "Epoch 3/200\n",
      "60000/60000 [==============================] - 2s 41us/step - loss: 0.5916 - val_loss: 0.5749\n",
      "Epoch 4/200\n",
      "60000/60000 [==============================] - 3s 42us/step - loss: 0.5598 - val_loss: 0.5454\n",
      "Epoch 5/200\n",
      "60000/60000 [==============================] - 2s 39us/step - loss: 0.5323 - val_loss: 0.5198\n",
      "Epoch 6/200\n",
      "60000/60000 [==============================] - 2s 39us/step - loss: 0.5084 - val_loss: 0.4975\n",
      "Epoch 7/200\n",
      "60000/60000 [==============================] - 2s 39us/step - loss: 0.4875 - val_loss: 0.4780\n",
      "Epoch 8/200\n",
      "60000/60000 [==============================] - 2s 40us/step - loss: 0.4692 - val_loss: 0.4609\n",
      "Epoch 9/200\n",
      "60000/60000 [==============================] - 2s 40us/step - loss: 0.4531 - val_loss: 0.4457\n",
      "Epoch 10/200\n",
      "60000/60000 [==============================] - 2s 40us/step - loss: 0.4389 - val_loss: 0.4324\n",
      "Epoch 11/200\n",
      "60000/60000 [==============================] - 2s 40us/step - loss: 0.4262 - val_loss: 0.4205\n",
      "Epoch 12/200\n",
      "60000/60000 [==============================] - 2s 40us/step - loss: 0.4150 - val_loss: 0.4098\n",
      "Epoch 13/200\n",
      "60000/60000 [==============================] - 2s 40us/step - loss: 0.4049 - val_loss: 0.4003\n",
      "Epoch 14/200\n",
      "60000/60000 [==============================] - 2s 39us/step - loss: 0.3959 - val_loss: 0.3918\n",
      "Epoch 15/200\n",
      "60000/60000 [==============================] - 2s 40us/step - loss: 0.3877 - val_loss: 0.3840\n",
      "Epoch 16/200\n",
      "60000/60000 [==============================] - 2s 40us/step - loss: 0.3804 - val_loss: 0.3771\n",
      "Epoch 17/200\n",
      "60000/60000 [==============================] - 2s 40us/step - loss: 0.3737 - val_loss: 0.3707\n",
      "Epoch 18/200\n",
      "60000/60000 [==============================] - 2s 42us/step - loss: 0.3676 - val_loss: 0.3649\n",
      "Epoch 19/200\n",
      "60000/60000 [==============================] - 2s 40us/step - loss: 0.3621 - val_loss: 0.3596\n",
      "Epoch 20/200\n",
      "60000/60000 [==============================] - 2s 41us/step - loss: 0.3570 - val_loss: 0.3548\n",
      "Epoch 21/200\n",
      "60000/60000 [==============================] - 3s 42us/step - loss: 0.3524 - val_loss: 0.3503\n",
      "Epoch 22/200\n",
      "60000/60000 [==============================] - 2s 41us/step - loss: 0.3481 - val_loss: 0.3463\n",
      "Epoch 23/200\n",
      "60000/60000 [==============================] - 2s 42us/step - loss: 0.3442 - val_loss: 0.3425\n",
      "Epoch 24/200\n",
      "60000/60000 [==============================] - 2s 40us/step - loss: 0.3406 - val_loss: 0.3390\n",
      "Epoch 25/200\n",
      "60000/60000 [==============================] - 2s 41us/step - loss: 0.3372 - val_loss: 0.3357\n",
      "Epoch 26/200\n",
      "60000/60000 [==============================] - 3s 43us/step - loss: 0.3341 - val_loss: 0.3327\n",
      "Epoch 27/200\n",
      "60000/60000 [==============================] - 2s 42us/step - loss: 0.3312 - val_loss: 0.3299\n",
      "Epoch 28/200\n",
      "60000/60000 [==============================] - 3s 44us/step - loss: 0.3285 - val_loss: 0.3273\n",
      "Epoch 29/200\n",
      "60000/60000 [==============================] - 3s 44us/step - loss: 0.3259 - val_loss: 0.3249\n",
      "Epoch 30/200\n",
      "60000/60000 [==============================] - 2s 40us/step - loss: 0.3236 - val_loss: 0.3226\n",
      "Epoch 31/200\n",
      "60000/60000 [==============================] - 2s 41us/step - loss: 0.3213 - val_loss: 0.3204\n",
      "Epoch 32/200\n",
      "60000/60000 [==============================] - 3s 43us/step - loss: 0.3193 - val_loss: 0.3184\n",
      "Epoch 33/200\n",
      "60000/60000 [==============================] - 2s 40us/step - loss: 0.3173 - val_loss: 0.3165\n",
      "Epoch 34/200\n",
      "60000/60000 [==============================] - 2s 41us/step - loss: 0.3155 - val_loss: 0.3147\n",
      "Epoch 35/200\n",
      "60000/60000 [==============================] - 3s 42us/step - loss: 0.3138 - val_loss: 0.3131\n",
      "Epoch 36/200\n",
      "60000/60000 [==============================] - 3s 43us/step - loss: 0.3121 - val_loss: 0.3115\n",
      "Epoch 37/200\n",
      "60000/60000 [==============================] - 3s 43us/step - loss: 0.3106 - val_loss: 0.3100\n",
      "Epoch 38/200\n",
      "60000/60000 [==============================] - 3s 44us/step - loss: 0.3091 - val_loss: 0.3085\n",
      "Epoch 39/200\n",
      "60000/60000 [==============================] - 3s 46us/step - loss: 0.3077 - val_loss: 0.3072\n",
      "Epoch 40/200\n",
      "60000/60000 [==============================] - 3s 50us/step - loss: 0.3064 - val_loss: 0.3059\n",
      "Epoch 41/200\n",
      "60000/60000 [==============================] - 3s 46us/step - loss: 0.3052 - val_loss: 0.3047\n",
      "Epoch 42/200\n",
      "60000/60000 [==============================] - 3s 45us/step - loss: 0.3040 - val_loss: 0.3035\n",
      "Epoch 43/200\n",
      "60000/60000 [==============================] - 3s 52us/step - loss: 0.3029 - val_loss: 0.3024\n",
      "Epoch 44/200\n",
      "60000/60000 [==============================] - 3s 48us/step - loss: 0.3018 - val_loss: 0.3014\n",
      "Epoch 45/200\n",
      "60000/60000 [==============================] - 3s 48us/step - loss: 0.3008 - val_loss: 0.3004\n",
      "Epoch 46/200\n",
      "60000/60000 [==============================] - 3s 43us/step - loss: 0.2998 - val_loss: 0.2994\n",
      "Epoch 47/200\n",
      "60000/60000 [==============================] - 3s 44us/step - loss: 0.2989 - val_loss: 0.2985\n",
      "Epoch 48/200\n",
      "60000/60000 [==============================] - 3s 50us/step - loss: 0.2980 - val_loss: 0.2976\n",
      "Epoch 49/200\n",
      "60000/60000 [==============================] - 4s 60us/step - loss: 0.2971 - val_loss: 0.2968\n",
      "Epoch 50/200\n",
      "60000/60000 [==============================] - 3s 53us/step - loss: 0.2963 - val_loss: 0.2960\n",
      "Epoch 51/200\n",
      "60000/60000 [==============================] - 3s 44us/step - loss: 0.2955 - val_loss: 0.2952\n",
      "Epoch 52/200\n",
      "60000/60000 [==============================] - 3s 43us/step - loss: 0.2948 - val_loss: 0.2945\n",
      "Epoch 53/200\n",
      "60000/60000 [==============================] - 3s 44us/step - loss: 0.2941 - val_loss: 0.2938\n",
      "Epoch 54/200\n",
      "60000/60000 [==============================] - 3s 43us/step - loss: 0.2934 - val_loss: 0.2931\n",
      "Epoch 55/200\n",
      "60000/60000 [==============================] - 3s 42us/step - loss: 0.2927 - val_loss: 0.2925\n",
      "Epoch 56/200\n",
      "60000/60000 [==============================] - 3s 43us/step - loss: 0.2921 - val_loss: 0.2918\n",
      "Epoch 57/200\n",
      "60000/60000 [==============================] - 3s 43us/step - loss: 0.2915 - val_loss: 0.2912\n",
      "Epoch 58/200\n",
      "60000/60000 [==============================] - 3s 42us/step - loss: 0.2909 - val_loss: 0.2906\n",
      "Epoch 59/200\n",
      "60000/60000 [==============================] - 3s 42us/step - loss: 0.2903 - val_loss: 0.2901\n",
      "Epoch 60/200\n",
      "60000/60000 [==============================] - 3s 44us/step - loss: 0.2898 - val_loss: 0.2895\n",
      "Epoch 61/200\n",
      "60000/60000 [==============================] - 3s 44us/step - loss: 0.2892 - val_loss: 0.2890\n",
      "Epoch 62/200\n",
      "60000/60000 [==============================] - 3s 45us/step - loss: 0.2887 - val_loss: 0.2885\n",
      "Epoch 63/200\n",
      "60000/60000 [==============================] - 3s 45us/step - loss: 0.2882 - val_loss: 0.2880\n",
      "Epoch 64/200\n",
      "60000/60000 [==============================] - 3s 43us/step - loss: 0.2877 - val_loss: 0.2875\n",
      "Epoch 65/200\n",
      "60000/60000 [==============================] - 3s 43us/step - loss: 0.2873 - val_loss: 0.2871\n",
      "Epoch 66/200\n",
      "60000/60000 [==============================] - 3s 44us/step - loss: 0.2868 - val_loss: 0.2867\n",
      "Epoch 67/200\n",
      "60000/60000 [==============================] - 3s 44us/step - loss: 0.2864 - val_loss: 0.2862\n",
      "Epoch 68/200\n",
      "60000/60000 [==============================] - 3s 44us/step - loss: 0.2860 - val_loss: 0.2858\n",
      "Epoch 69/200\n",
      "60000/60000 [==============================] - 3s 44us/step - loss: 0.2856 - val_loss: 0.2854\n",
      "Epoch 70/200\n",
      "60000/60000 [==============================] - 3s 44us/step - loss: 0.2852 - val_loss: 0.2850\n",
      "Epoch 71/200\n",
      "60000/60000 [==============================] - 3s 43us/step - loss: 0.2848 - val_loss: 0.2846\n",
      "Epoch 72/200\n",
      "60000/60000 [==============================] - 3s 44us/step - loss: 0.2844 - val_loss: 0.2843\n",
      "Epoch 73/200\n",
      "60000/60000 [==============================] - 3s 44us/step - loss: 0.2841 - val_loss: 0.2839\n",
      "Epoch 74/200\n",
      "60000/60000 [==============================] - 3s 43us/step - loss: 0.2837 - val_loss: 0.2836\n",
      "Epoch 75/200\n",
      "60000/60000 [==============================] - 3s 44us/step - loss: 0.2834 - val_loss: 0.2832\n",
      "Epoch 76/200\n",
      "60000/60000 [==============================] - 3s 44us/step - loss: 0.2831 - val_loss: 0.2829\n",
      "Epoch 77/200\n",
      "60000/60000 [==============================] - 3s 45us/step - loss: 0.2828 - val_loss: 0.2826\n",
      "Epoch 78/200\n",
      "60000/60000 [==============================] - 3s 45us/step - loss: 0.2825 - val_loss: 0.2823\n",
      "Epoch 79/200\n",
      "60000/60000 [==============================] - 3s 44us/step - loss: 0.2822 - val_loss: 0.2820\n",
      "Epoch 80/200\n",
      "60000/60000 [==============================] - 3s 48us/step - loss: 0.2819 - val_loss: 0.2817\n",
      "Epoch 81/200\n",
      "60000/60000 [==============================] - 3s 46us/step - loss: 0.2816 - val_loss: 0.2814\n",
      "Epoch 82/200\n",
      "60000/60000 [==============================] - 3s 47us/step - loss: 0.2813 - val_loss: 0.2812\n",
      "Epoch 83/200\n",
      "60000/60000 [==============================] - 3s 49us/step - loss: 0.2810 - val_loss: 0.2809\n",
      "Epoch 84/200\n",
      "60000/60000 [==============================] - 3s 50us/step - loss: 0.2808 - val_loss: 0.2806\n",
      "Epoch 85/200\n",
      "60000/60000 [==============================] - 3s 46us/step - loss: 0.2805 - val_loss: 0.2804\n",
      "Epoch 86/200\n",
      "60000/60000 [==============================] - 3s 44us/step - loss: 0.2803 - val_loss: 0.2801\n",
      "Epoch 87/200\n",
      "60000/60000 [==============================] - 3s 43us/step - loss: 0.2800 - val_loss: 0.2799\n",
      "Epoch 88/200\n",
      "60000/60000 [==============================] - 3s 44us/step - loss: 0.2798 - val_loss: 0.2796\n",
      "Epoch 89/200\n",
      "60000/60000 [==============================] - 3s 44us/step - loss: 0.2796 - val_loss: 0.2794\n",
      "Epoch 90/200\n",
      "60000/60000 [==============================] - 3s 46us/step - loss: 0.2793 - val_loss: 0.2792\n",
      "Epoch 91/200\n",
      "60000/60000 [==============================] - 3s 51us/step - loss: 0.2791 - val_loss: 0.2790\n",
      "Epoch 92/200\n",
      "60000/60000 [==============================] - 3s 49us/step - loss: 0.2789 - val_loss: 0.2788\n",
      "Epoch 93/200\n",
      "60000/60000 [==============================] - 3s 52us/step - loss: 0.2787 - val_loss: 0.2785\n",
      "Epoch 94/200\n",
      "60000/60000 [==============================] - 3s 48us/step - loss: 0.2785 - val_loss: 0.2783\n",
      "Epoch 95/200\n",
      "60000/60000 [==============================] - 3s 47us/step - loss: 0.2783 - val_loss: 0.2781\n",
      "Epoch 96/200\n",
      "60000/60000 [==============================] - 3s 49us/step - loss: 0.2781 - val_loss: 0.2779\n",
      "Epoch 97/200\n",
      "60000/60000 [==============================] - 3s 51us/step - loss: 0.2779 - val_loss: 0.2778\n",
      "Epoch 98/200\n",
      "60000/60000 [==============================] - 3s 47us/step - loss: 0.2777 - val_loss: 0.2776\n",
      "Epoch 99/200\n",
      "60000/60000 [==============================] - 3s 48us/step - loss: 0.2775 - val_loss: 0.2774\n",
      "Epoch 100/200\n",
      "60000/60000 [==============================] - 3s 50us/step - loss: 0.2774 - val_loss: 0.2772\n",
      "Epoch 101/200\n",
      "60000/60000 [==============================] - 3s 47us/step - loss: 0.2772 - val_loss: 0.2770\n",
      "Epoch 102/200\n",
      "60000/60000 [==============================] - 3s 46us/step - loss: 0.2770 - val_loss: 0.2769\n",
      "Epoch 103/200\n",
      "60000/60000 [==============================] - 3s 53us/step - loss: 0.2768 - val_loss: 0.2767\n",
      "Epoch 104/200\n",
      "60000/60000 [==============================] - 3s 46us/step - loss: 0.2767 - val_loss: 0.2765\n",
      "Epoch 105/200\n",
      "60000/60000 [==============================] - 3s 51us/step - loss: 0.2765 - val_loss: 0.2764\n",
      "Epoch 106/200\n",
      "60000/60000 [==============================] - 3s 50us/step - loss: 0.2764 - val_loss: 0.2762\n",
      "Epoch 107/200\n",
      "60000/60000 [==============================] - 3s 50us/step - loss: 0.2762 - val_loss: 0.2761\n",
      "Epoch 108/200\n",
      "60000/60000 [==============================] - 3s 48us/step - loss: 0.2761 - val_loss: 0.2759\n",
      "Epoch 109/200\n",
      "60000/60000 [==============================] - 3s 48us/step - loss: 0.2759 - val_loss: 0.2758\n",
      "Epoch 110/200\n",
      "60000/60000 [==============================] - 3s 47us/step - loss: 0.2758 - val_loss: 0.2756\n",
      "Epoch 111/200\n",
      "60000/60000 [==============================] - 3s 47us/step - loss: 0.2756 - val_loss: 0.2755\n",
      "Epoch 112/200\n",
      "60000/60000 [==============================] - 3s 47us/step - loss: 0.2755 - val_loss: 0.2753\n",
      "Epoch 113/200\n",
      "60000/60000 [==============================] - 3s 48us/step - loss: 0.2754 - val_loss: 0.2752\n",
      "Epoch 114/200\n",
      "60000/60000 [==============================] - 3s 45us/step - loss: 0.2752 - val_loss: 0.2751\n",
      "Epoch 115/200\n",
      "60000/60000 [==============================] - 3s 44us/step - loss: 0.2751 - val_loss: 0.2749\n",
      "Epoch 116/200\n",
      "60000/60000 [==============================] - 3s 45us/step - loss: 0.2750 - val_loss: 0.2748\n",
      "Epoch 117/200\n",
      "60000/60000 [==============================] - 3s 45us/step - loss: 0.2748 - val_loss: 0.2747\n",
      "Epoch 118/200\n",
      "60000/60000 [==============================] - 3s 45us/step - loss: 0.2747 - val_loss: 0.2746\n",
      "Epoch 119/200\n",
      "60000/60000 [==============================] - 4s 60us/step - loss: 0.2746 - val_loss: 0.2744\n",
      "Epoch 120/200\n",
      "60000/60000 [==============================] - 3s 52us/step - loss: 0.2745 - val_loss: 0.2743\n",
      "Epoch 121/200\n",
      "60000/60000 [==============================] - 3s 43us/step - loss: 0.2744 - val_loss: 0.2742\n",
      "Epoch 122/200\n",
      "60000/60000 [==============================] - 3s 46us/step - loss: 0.2742 - val_loss: 0.2741\n",
      "Epoch 123/200\n",
      "60000/60000 [==============================] - 3s 54us/step - loss: 0.2741 - val_loss: 0.2740\n",
      "Epoch 124/200\n",
      "60000/60000 [==============================] - 3s 55us/step - loss: 0.2740 - val_loss: 0.2739\n",
      "Epoch 125/200\n",
      "60000/60000 [==============================] - 3s 43us/step - loss: 0.2739 - val_loss: 0.2738\n",
      "Epoch 126/200\n",
      "60000/60000 [==============================] - 3s 46us/step - loss: 0.2738 - val_loss: 0.2737\n",
      "Epoch 127/200\n",
      "60000/60000 [==============================] - 3s 44us/step - loss: 0.2737 - val_loss: 0.2736\n",
      "Epoch 128/200\n",
      "60000/60000 [==============================] - 3s 42us/step - loss: 0.2736 - val_loss: 0.2734\n",
      "Epoch 129/200\n",
      "60000/60000 [==============================] - 2s 41us/step - loss: 0.2735 - val_loss: 0.2733\n",
      "Epoch 130/200\n",
      "60000/60000 [==============================] - 3s 46us/step - loss: 0.2734 - val_loss: 0.2732\n",
      "Epoch 131/200\n",
      "60000/60000 [==============================] - 3s 45us/step - loss: 0.2733 - val_loss: 0.2731\n",
      "Epoch 132/200\n",
      "60000/60000 [==============================] - 2s 42us/step - loss: 0.2732 - val_loss: 0.2731\n",
      "Epoch 133/200\n",
      "60000/60000 [==============================] - 3s 43us/step - loss: 0.2731 - val_loss: 0.2730\n",
      "Epoch 134/200\n",
      "60000/60000 [==============================] - 3s 42us/step - loss: 0.2730 - val_loss: 0.2729\n",
      "Epoch 135/200\n",
      "60000/60000 [==============================] - 3s 42us/step - loss: 0.2729 - val_loss: 0.2728\n",
      "Epoch 136/200\n",
      "60000/60000 [==============================] - 3s 42us/step - loss: 0.2728 - val_loss: 0.2727\n",
      "Epoch 137/200\n",
      "60000/60000 [==============================] - 2s 41us/step - loss: 0.2728 - val_loss: 0.2726\n",
      "Epoch 138/200\n",
      "60000/60000 [==============================] - 3s 45us/step - loss: 0.2727 - val_loss: 0.2725\n",
      "Epoch 139/200\n",
      "60000/60000 [==============================] - 3s 43us/step - loss: 0.2726 - val_loss: 0.2724\n",
      "Epoch 140/200\n",
      "60000/60000 [==============================] - 3s 44us/step - loss: 0.2725 - val_loss: 0.2723\n",
      "Epoch 141/200\n",
      "60000/60000 [==============================] - 3s 44us/step - loss: 0.2724 - val_loss: 0.2723\n",
      "Epoch 142/200\n",
      "60000/60000 [==============================] - 3s 42us/step - loss: 0.2723 - val_loss: 0.2722\n",
      "Epoch 143/200\n",
      "60000/60000 [==============================] - 3s 43us/step - loss: 0.2722 - val_loss: 0.2721\n",
      "Epoch 144/200\n",
      "60000/60000 [==============================] - 3s 43us/step - loss: 0.2722 - val_loss: 0.2720\n",
      "Epoch 145/200\n",
      "60000/60000 [==============================] - 3s 42us/step - loss: 0.2721 - val_loss: 0.2719\n",
      "Epoch 146/200\n",
      "60000/60000 [==============================] - 2s 42us/step - loss: 0.2720 - val_loss: 0.2719\n",
      "Epoch 147/200\n",
      "60000/60000 [==============================] - 3s 42us/step - loss: 0.2719 - val_loss: 0.2718\n",
      "Epoch 148/200\n",
      "60000/60000 [==============================] - 3s 43us/step - loss: 0.2719 - val_loss: 0.2717\n",
      "Epoch 149/200\n",
      "60000/60000 [==============================] - 3s 44us/step - loss: 0.2718 - val_loss: 0.2716\n",
      "Epoch 150/200\n",
      "60000/60000 [==============================] - 3s 42us/step - loss: 0.2717 - val_loss: 0.2716\n",
      "Epoch 151/200\n",
      "60000/60000 [==============================] - 3s 43us/step - loss: 0.2716 - val_loss: 0.2715\n",
      "Epoch 152/200\n",
      "60000/60000 [==============================] - 2s 41us/step - loss: 0.2716 - val_loss: 0.2714\n",
      "Epoch 153/200\n",
      "60000/60000 [==============================] - 3s 42us/step - loss: 0.2715 - val_loss: 0.2713\n",
      "Epoch 154/200\n",
      "60000/60000 [==============================] - 2s 42us/step - loss: 0.2714 - val_loss: 0.2713\n",
      "Epoch 155/200\n",
      "60000/60000 [==============================] - 3s 47us/step - loss: 0.2714 - val_loss: 0.2712\n",
      "Epoch 156/200\n",
      "60000/60000 [==============================] - 3s 44us/step - loss: 0.2713 - val_loss: 0.2711\n",
      "Epoch 157/200\n",
      "60000/60000 [==============================] - 3s 42us/step - loss: 0.2712 - val_loss: 0.2711\n",
      "Epoch 158/200\n",
      "60000/60000 [==============================] - 3s 43us/step - loss: 0.2712 - val_loss: 0.2710\n",
      "Epoch 159/200\n",
      "60000/60000 [==============================] - 3s 44us/step - loss: 0.2711 - val_loss: 0.2709\n",
      "Epoch 160/200\n",
      "60000/60000 [==============================] - 3s 44us/step - loss: 0.2711 - val_loss: 0.2709\n",
      "Epoch 161/200\n",
      "60000/60000 [==============================] - 3s 42us/step - loss: 0.2710 - val_loss: 0.2708\n",
      "Epoch 162/200\n",
      "60000/60000 [==============================] - 3s 43us/step - loss: 0.2709 - val_loss: 0.2708\n",
      "Epoch 163/200\n",
      "60000/60000 [==============================] - 3s 42us/step - loss: 0.2709 - val_loss: 0.2707\n",
      "Epoch 164/200\n",
      "60000/60000 [==============================] - 3s 42us/step - loss: 0.2708 - val_loss: 0.2706\n",
      "Epoch 165/200\n",
      "60000/60000 [==============================] - 3s 45us/step - loss: 0.2708 - val_loss: 0.2706\n",
      "Epoch 166/200\n",
      "60000/60000 [==============================] - 3s 45us/step - loss: 0.2707 - val_loss: 0.2705\n",
      "Epoch 167/200\n",
      "60000/60000 [==============================] - 3s 47us/step - loss: 0.2706 - val_loss: 0.2705\n",
      "Epoch 168/200\n",
      "60000/60000 [==============================] - 3s 44us/step - loss: 0.2706 - val_loss: 0.2704\n",
      "Epoch 169/200\n",
      "60000/60000 [==============================] - 3s 42us/step - loss: 0.2705 - val_loss: 0.2704\n",
      "Epoch 170/200\n",
      "60000/60000 [==============================] - 3s 43us/step - loss: 0.2705 - val_loss: 0.2703\n",
      "Epoch 171/200\n",
      "60000/60000 [==============================] - 3s 42us/step - loss: 0.2704 - val_loss: 0.2702\n",
      "Epoch 172/200\n",
      "60000/60000 [==============================] - 3s 44us/step - loss: 0.2704 - val_loss: 0.2702\n",
      "Epoch 173/200\n",
      "60000/60000 [==============================] - 2s 41us/step - loss: 0.2703 - val_loss: 0.2701\n",
      "Epoch 174/200\n",
      "60000/60000 [==============================] - 3s 42us/step - loss: 0.2703 - val_loss: 0.2701\n",
      "Epoch 175/200\n",
      "60000/60000 [==============================] - 3s 44us/step - loss: 0.2702 - val_loss: 0.2700\n",
      "Epoch 176/200\n",
      "60000/60000 [==============================] - 3s 43us/step - loss: 0.2702 - val_loss: 0.2700\n",
      "Epoch 177/200\n",
      "60000/60000 [==============================] - 3s 42us/step - loss: 0.2701 - val_loss: 0.2699\n",
      "Epoch 178/200\n",
      "60000/60000 [==============================] - 3s 47us/step - loss: 0.2701 - val_loss: 0.2699\n",
      "Epoch 179/200\n",
      "60000/60000 [==============================] - 3s 43us/step - loss: 0.2700 - val_loss: 0.2698\n",
      "Epoch 180/200\n",
      "60000/60000 [==============================] - 3s 42us/step - loss: 0.2700 - val_loss: 0.2698\n",
      "Epoch 181/200\n",
      "60000/60000 [==============================] - 3s 43us/step - loss: 0.2699 - val_loss: 0.2697\n",
      "Epoch 182/200\n",
      "60000/60000 [==============================] - 3s 43us/step - loss: 0.2699 - val_loss: 0.2697\n",
      "Epoch 183/200\n",
      "60000/60000 [==============================] - 3s 46us/step - loss: 0.2698 - val_loss: 0.2696\n",
      "Epoch 184/200\n",
      "60000/60000 [==============================] - 3s 50us/step - loss: 0.2698 - val_loss: 0.2696\n",
      "Epoch 185/200\n",
      "60000/60000 [==============================] - 3s 43us/step - loss: 0.2697 - val_loss: 0.2695\n",
      "Epoch 186/200\n",
      "60000/60000 [==============================] - 3s 44us/step - loss: 0.2697 - val_loss: 0.2695\n",
      "Epoch 187/200\n",
      "60000/60000 [==============================] - 3s 42us/step - loss: 0.2696 - val_loss: 0.2695\n",
      "Epoch 188/200\n",
      "60000/60000 [==============================] - 3s 42us/step - loss: 0.2696 - val_loss: 0.2694\n",
      "Epoch 189/200\n",
      "60000/60000 [==============================] - 3s 43us/step - loss: 0.2696 - val_loss: 0.2694\n",
      "Epoch 190/200\n",
      "60000/60000 [==============================] - 3s 42us/step - loss: 0.2695 - val_loss: 0.2693\n",
      "Epoch 191/200\n",
      "60000/60000 [==============================] - 3s 44us/step - loss: 0.2695 - val_loss: 0.2693\n",
      "Epoch 192/200\n",
      "60000/60000 [==============================] - 3s 45us/step - loss: 0.2694 - val_loss: 0.2692\n",
      "Epoch 193/200\n",
      "60000/60000 [==============================] - 3s 43us/step - loss: 0.2694 - val_loss: 0.2692\n",
      "Epoch 194/200\n",
      "60000/60000 [==============================] - 3s 42us/step - loss: 0.2693 - val_loss: 0.2692\n",
      "Epoch 195/200\n",
      "60000/60000 [==============================] - 3s 45us/step - loss: 0.2693 - val_loss: 0.2691\n",
      "Epoch 196/200\n",
      "60000/60000 [==============================] - 3s 42us/step - loss: 0.2693 - val_loss: 0.2691\n",
      "Epoch 197/200\n",
      "60000/60000 [==============================] - 2s 41us/step - loss: 0.2692 - val_loss: 0.2690\n",
      "Epoch 198/200\n",
      "60000/60000 [==============================] - 3s 48us/step - loss: 0.2692 - val_loss: 0.2690\n",
      "Epoch 199/200\n",
      "60000/60000 [==============================] - 3s 43us/step - loss: 0.2691 - val_loss: 0.2690\n",
      "Epoch 200/200\n",
      "60000/60000 [==============================] - 3s 43us/step - loss: 0.2691 - val_loss: 0.2689\n"
     ]
    }
   ],
   "source": [
    "autoencoder.fit(x_train, x_train,\n",
    "                epochs=200,\n",
    "                batch_size=256,\n",
    "                shuffle=True,\n",
    "                validation_data=(x_test, x_test))\n",
    "autoencoder.save(\"./autoencoder_l1.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# encode and decode some digits\n",
    "# note that we take them from the *test* set\n",
    "encoded_imgs = encoder.predict(x_test)\n",
    "decoded_imgs = decoder.predict(encoded_imgs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1440x288 with 20 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# use Matplotlib (don't ask)\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "n = 10  # how many digits we will display\n",
    "plt.figure(figsize=(20, 4))\n",
    "for i in range(n):\n",
    "    # display original\n",
    "    ax = plt.subplot(2, n, i + 1)\n",
    "    plt.imshow(x_test[i].reshape(28, 28))\n",
    "    plt.gray()\n",
    "    ax.get_xaxis().set_visible(False)\n",
    "    ax.get_yaxis().set_visible(False)\n",
    "\n",
    "    # display reconstruction\n",
    "    ax = plt.subplot(2, n, i + 1 + n)\n",
    "    plt.imshow(decoded_imgs[i].reshape(28, 28))\n",
    "    plt.gray()\n",
    "    ax.get_xaxis().set_visible(False)\n",
    "    ax.get_yaxis().set_visible(False)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
